{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24cefc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10742be",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = 'asl_dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31346743",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "img_size = 32\n",
    "validation_split = 0.2\n",
    "test_split = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e44af0e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Function to load images and labels using OpenCV\n",
    "def load_images_from_directory(directory_path, img_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(directory_path))  # Get sorted class names\n",
    "    for label, class_name in enumerate(class_names):\n",
    "        class_dir = os.path.join(directory_path, class_name)\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            img = cv2.imread(img_path)  # Load image using OpenCV\n",
    "            img = cv2.flip(img, 1)  # Flip image horizontally (mirror-wise)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "            img = cv2.GaussianBlur(img, (15, 15), 0)  # Apply Gaussian blur\n",
    "            _, img = cv2.threshold(img, 161, 255, cv2.THRESH_BINARY)  # Apply thresholding\n",
    "            img = cv2.resize(img, (img_size, img_size))  # Resize image\n",
    "            img = img.astype('float32') / 255.0  # Normalize image\n",
    "            images.append(img)\n",
    "            labels.append(label)  # Append corresponding label\n",
    "    return np.array(images), np.array(labels), class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a347ce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset using OpenCV\n",
    "images, labels, class_names = load_images_from_directory(directory_path, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d06d5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a channel dimension to images for grayscale (necessary for CNN models)\n",
    "images = np.expand_dims(images, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceaeb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training, validation, and test sets\n",
    "train_images, temp_images, train_labels, temp_labels = train_test_split(\n",
    "    images, labels, test_size=(validation_split + test_split), random_state=123, stratify=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27986257",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = validation_split / (validation_split + test_split)  # Adjust validation size relative to temp set\n",
    "val_images, test_images, val_labels, test_labels = train_test_split(\n",
    "    temp_images, temp_labels, test_size=val_size, random_state=123, stratify=temp_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1764885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print class names to check\n",
    "print(\"Class Names:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfce5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset to .npz (compressed format) for later use\n",
    "np.savez_compressed('asl_dataset.npz', \n",
    "                    train_images=train_images, train_labels=train_labels,\n",
    "                    val_images=val_images, val_labels=val_labels,\n",
    "                    test_images=test_images, test_labels=test_labels,\n",
    "                    class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67d1c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 24 sample images from the training set\n",
    "plt.figure(figsize=(12, 5))\n",
    "for i in range(24):\n",
    "    plt.subplot(3, 8, i + 1)\n",
    "    plt.imshow(train_images[i].squeeze(), cmap='gray')  # Squeeze to remove channel dimension for grayscale\n",
    "    plt.title(class_names[train_labels[i]])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
