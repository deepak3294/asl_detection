{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b1e6dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11570388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- A. CONFIGURATION ---\n",
    "# Initialize MediaPipe hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, min_detection_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4dd9a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of letters to capture (excluding J and Z for static ASL)\n",
    "letters = 'ABCDEFGHIKLMNOPQRSTUVWXY'\n",
    "NUM_IMAGES_PER_CLASS = 150 # Total images to capture for each letter\n",
    "DATASET_DIR = 'asl_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e12cd93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- B. ROI DEFINITION (CRITICAL FOR TRAINING CONSISTENCY) ---\n",
    "# Define the fixed Region of Interest (ROI) boundaries on the right side of the screen\n",
    "# Coordinates (normalized to a 640x480 frame for drawing)\n",
    "ROI_START_X, ROI_START_Y = 400, 50 \n",
    "ROI_END_X, ROI_END_Y = 600, 350\n",
    "ROI_COLOR = (255, 0, 0) # Blue for the ROI box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53f5c7a2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(DATASET_DIR):\n",
    "    os.makedirs(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e80d70",
   "metadata": {},
   "source": [
    "--- C. CAPTURE FUNCTION ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1589cc60",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def capture_images_for_letter(letter, num_images=NUM_IMAGES_PER_CLASS):\n",
    "    letter_dir = os.path.join(DATASET_DIR, letter)\n",
    "    if not os.path.exists(letter_dir):\n",
    "        os.makedirs(letter_dir)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    # Set standard frame size for consistent ROI drawing\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n--- Ready to capture {letter}. Hold sign and press 'S' ---\")\n",
    "\n",
    "    count = 0\n",
    "    while count < num_images:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        \n",
    "        # Flip the frame and get dimensions\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        h, w, _ = frame.shape\n",
    "        \n",
    "        # Draw the Fixed ROI Box\n",
    "        cv2.rectangle(frame, (ROI_START_X, ROI_START_Y), (ROI_END_X, ROI_END_Y), ROI_COLOR, 2)\n",
    "        \n",
    "        # Display status\n",
    "        status_text = f\"Class: {letter} | Captured: {count}/{num_images}\"\n",
    "        cv2.putText(frame, status_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        # Convert to RGB and process with MediaPipe\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(frame_rgb)\n",
    "        \n",
    "        # --- LOGIC TO CHECK ROI AND CROP ---\n",
    "        \n",
    "        hand_detected_in_roi = False\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # 1. Calculate the center of the detected hand\n",
    "                x_center_normalized = sum(lm.x for lm in hand_landmarks.landmark) / len(hand_landmarks.landmark)\n",
    "                y_center_normalized = sum(lm.y for lm in hand_landmarks.landmark) / len(hand_landmarks.landmark)\n",
    "                \n",
    "                x_center = int(x_center_normalized * w)\n",
    "                y_center = int(y_center_normalized * h)\n",
    "                \n",
    "                # 2. Check if the hand center is within the Fixed ROI box\n",
    "                if (ROI_START_X < x_center < ROI_END_X) and (ROI_START_Y < y_center < ROI_END_Y):\n",
    "                    \n",
    "                    # Hand is correctly positioned in the box\n",
    "                    hand_detected_in_roi = True\n",
    "                    \n",
    "                    # Determine the bounding box coordinates (similar to your old logic)\n",
    "                    x_min = int(min(lm.x for lm in hand_landmarks.landmark) * w)\n",
    "                    x_max = int(max(lm.x for lm in hand_landmarks.landmark) * w)\n",
    "                    y_min = int(min(lm.y for lm in hand_landmarks.landmark) * h)\n",
    "                    y_max = int(max(lm.y for lm in hand_landmarks.landmark) * h)\n",
    "                    \n",
    "                    # Apply margin and clip to frame boundaries\n",
    "                    box_margin = 20\n",
    "                    x_min = max(x_min - box_margin, 0)\n",
    "                    x_max = min(x_max + box_margin, w)\n",
    "                    y_min = max(y_min - box_margin, 0)\n",
    "                    y_max = min(y_max + box_margin, h)\n",
    "                    \n",
    "                    # Draw a GREEN box for confirmation\n",
    "                    cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "                    \n",
    "                    # Crop the hand region\n",
    "                    hand_region = frame[y_min:y_max, x_min:x_max]\n",
    "                    \n",
    "                    # --- SAVE ACTION ---\n",
    "                    img_path = os.path.join(letter_dir, f'{letter}_{count}_{time.time()}.jpg')\n",
    "                    cv2.imwrite(img_path, hand_region)\n",
    "                    count += 1\n",
    "                    break # Only save one hand per frame\n",
    "\n",
    "        # Draw status message if outside ROI\n",
    "        if not hand_detected_in_roi:\n",
    "            cv2.putText(frame, \"MOVE HAND INTO BLUE BOX\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            \n",
    "        cv2.imshow('ASL Data Collector', frame)\n",
    "\n",
    "        # Break the capture loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"Captured {count} images for letter {letter}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87c68c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ready for letter A. Press Enter in the terminal to begin capturing.\n",
      "\n",
      "--- Ready to capture A. Hold sign and press 'S' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\asl_detection1\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured 150 images for letter A.\n",
      "\n",
      "Ready for letter B. Press Enter in the terminal to begin capturing.\n",
      "\n",
      "--- Ready to capture B. Hold sign and press 'S' ---\n",
      "Captured 150 images for letter B.\n",
      "\n",
      "Ready for letter C. Press Enter in the terminal to begin capturing.\n",
      "\n",
      "--- Ready to capture C. Hold sign and press 'S' ---\n",
      "Captured 150 images for letter C.\n",
      "\n",
      "Ready for letter D. Press Enter in the terminal to begin capturing.\n",
      "\n",
      "--- Ready to capture D. Hold sign and press 'S' ---\n",
      "Captured 150 images for letter D.\n",
      "\n",
      "Ready for letter E. Press Enter in the terminal to begin capturing.\n",
      "\n",
      "--- Ready to capture E. Hold sign and press 'S' ---\n",
      "Captured 150 images for letter E.\n",
      "\n",
      "Ready for letter F. Press Enter in the terminal to begin capturing.\n",
      "\n",
      "--- Ready to capture F. Hold sign and press 'S' ---\n",
      "Captured 150 images for letter F.\n",
      "\n",
      "Ready for letter G. Press Enter in the terminal to begin capturing.\n",
      "\n",
      "--- Ready to capture G. Hold sign and press 'S' ---\n",
      "Captured 150 images for letter G.\n",
      "\n",
      "Ready for letter H. Press Enter in the terminal to begin capturing.\n",
      "\n",
      "--- Ready to capture H. Hold sign and press 'S' ---\n",
      "Captured 150 images for letter H.\n",
      "\n",
      "Ready for letter I. Press Enter in the terminal to begin capturing.\n",
      "\n",
      "--- Ready to capture I. Hold sign and press 'S' ---\n",
      "Captured 150 images for letter I.\n",
      "\n",
      "Ready for letter K. Press Enter in the terminal to begin capturing.\n",
      "\n",
      "--- Ready to capture K. Hold sign and press 'S' ---\n",
      "Captured 150 images for letter K.\n",
      "\n",
      "Ready for letter L. Press Enter in the terminal to begin capturing.\n",
      "\n",
      "--- Ready to capture L. Hold sign and press 'S' ---\n",
      "Captured 150 images for letter L.\n",
      "\n",
      "Ready for letter M. Press Enter in the terminal to begin capturing.\n",
      "\n",
      "--- Ready to capture M. Hold sign and press 'S' ---\n",
      "Captured 150 images for letter M.\n",
      "\n",
      "Ready for letter N. Press Enter in the terminal to begin capturing.\n",
      "\n",
      "--- Ready to capture N. Hold sign and press 'S' ---\n",
      "Captured 150 images for letter N.\n",
      "\n",
      "Ready for letter O. Press Enter in the terminal to begin capturing.\n",
      "\n",
      "--- Ready to capture O. Hold sign and press 'S' ---\n",
      "Captured 150 images for letter O.\n",
      "\n",
      "Ready for letter P. Press Enter in the terminal to begin capturing.\n",
      "\n",
      "--- Ready to capture P. Hold sign and press 'S' ---\n",
      "Captured 150 images for letter P.\n",
      "\n",
      "Ready for letter Q. Press Enter in the terminal to begin capturing.\n",
      "\n",
      "--- Ready to capture Q. Hold sign and press 'S' ---\n",
      "Captured 150 images for letter Q.\n",
      "\n",
      "Ready for letter R. Press Enter in the terminal to begin capturing.\n",
      "\n",
      "--- Ready to capture R. Hold sign and press 'S' ---\n",
      "Captured 150 images for letter R.\n",
      "\n",
      "Ready for letter S. Press Enter in the terminal to begin capturing.\n",
      "\n",
      "--- Ready to capture S. Hold sign and press 'S' ---\n",
      "Captured 150 images for letter S.\n",
      "\n",
      "Ready for letter T. Press Enter in the terminal to begin capturing.\n",
      "\n",
      "--- Ready to capture T. Hold sign and press 'S' ---\n",
      "Captured 150 images for letter T.\n",
      "\n",
      "Ready for letter U. Press Enter in the terminal to begin capturing.\n",
      "\n",
      "--- Ready to capture U. Hold sign and press 'S' ---\n",
      "Captured 150 images for letter U.\n",
      "\n",
      "Ready for letter V. Press Enter in the terminal to begin capturing.\n",
      "\n",
      "--- Ready to capture V. Hold sign and press 'S' ---\n",
      "Captured 150 images for letter V.\n",
      "\n",
      "Ready for letter W. Press Enter in the terminal to begin capturing.\n",
      "\n",
      "--- Ready to capture W. Hold sign and press 'S' ---\n",
      "Captured 150 images for letter W.\n",
      "\n",
      "Ready for letter X. Press Enter in the terminal to begin capturing.\n",
      "\n",
      "--- Ready to capture X. Hold sign and press 'S' ---\n",
      "Captured 150 images for letter X.\n",
      "\n",
      "Ready for letter Y. Press Enter in the terminal to begin capturing.\n",
      "\n",
      "--- Ready to capture Y. Hold sign and press 'S' ---\n",
      "Captured 150 images for letter Y.\n",
      "Dataset creation complete!\n"
     ]
    }
   ],
   "source": [
    "# --- D. LOOP EXECUTION ---\n",
    "if __name__ == '__main__':\n",
    "    for letter in letters:\n",
    "        # Before starting capture for the next letter, wait for user confirmation\n",
    "        print(f\"\\nReady for letter {letter}. Press Enter in the terminal to begin capturing.\")\n",
    "        input() # Wait for user input in the console\n",
    "        capture_images_for_letter(letter)\n",
    "\n",
    "    print(\"Dataset creation complete!\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
